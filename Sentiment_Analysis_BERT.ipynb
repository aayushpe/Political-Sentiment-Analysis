{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMD9KiGhvgRYuvB9ZYXGcGM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayushpe/Political-Sentiment-Analysis/blob/main/Sentiment_Analysis_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "RfKQi_SNZtIw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wfzQ5TkLMC2"
      },
      "outputs": [],
      "source": [
        "# Import dependencies\n",
        "!pip install datasets\n",
        "from transformers import TFAutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from datasets import load_dataset # In order to import test dataset, may have to run !pip install datasets\n",
        "import tensorflow as tf\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import BERT model, you need a hugging face account key\n",
        "model = TFAutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Import tokenizer to transform a sentence into features\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "2MnHPQ-Xz5yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenized Strings Examples"
      ],
      "metadata": {
        "id": "GdYwWfRk0YA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a sample sentence to test with the Bert Model.\n",
        "inputs = tokenizer('It was ok, it was not too great', padding=True, truncation=True, return_tensors='tf')\n",
        "print(inputs) # Visualize tokenized string"
      ],
      "metadata": {
        "id": "RujYzKTw0EZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Send string to model\n",
        "output = model(inputs)\n",
        "print(output) # Visualize model output"
      ],
      "metadata": {
        "id": "J78orjhW3Hdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import emotions dataset\n",
        "emotions = load_dataset('SetFit/emotion')\n",
        "print(emotions) # View dataset"
      ],
      "metadata": {
        "id": "LzETTiyk3V8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize dataset\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
        "\n",
        "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"
      ],
      "metadata": {
        "id": "ZM4Nnx543Z1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting 'input_ids', 'attention_mask', 'token_type_ids', and 'label'\n",
        "# to the tensorflow format. Now if you access this dataset you will get these\n",
        "# columns in `tf.Tensor` format\n",
        "\n",
        "emotions_encoded.set_format('tf',\n",
        "                            columns=['input_ids', 'attention_mask', 'token_type_ids', 'label'])\n",
        "\n",
        "# setting BATCH_SIZE to 64.\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def order(inp):\n",
        "    '''\n",
        "    This function will group all the inputs of BERT\n",
        "    into a single dictionary and then output it with\n",
        "    labels.\n",
        "    '''\n",
        "    data = list(inp.values())\n",
        "    return {\n",
        "        'input_ids': data[1],\n",
        "        'attention_mask': data[2],\n",
        "        'token_type_ids': data[3]\n",
        "    }, data[0]\n",
        "\n",
        "# converting train split of `emotions_encoded` to tensorflow format\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(emotions_encoded['train'][:])\n",
        "# set batch_size and shuffle\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).shuffle(1000)\n",
        "# map the `order` function\n",
        "train_dataset = train_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# ... doing the same for test set ...\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(emotions_encoded['test'][:])\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "MWn1vOhZ3o-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp, out = next(iter(train_dataset)) # a batch from train_dataset\n",
        "print(inp, '\\n\\n', out)"
      ],
      "metadata": {
        "id": "1fLO9UsL3q5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate model\n",
        "class BERTForClassification(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, bert_model, num_classes):\n",
        "        super().__init__()\n",
        "        self.bert = bert_model\n",
        "        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bert(inputs)[1]\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "2FOp6cSX3uHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = BERTForClassification(model, num_classes=6)\n",
        "\n",
        "# Specify the models' optimizer and loss function\n",
        "classifier.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "EHadwV4e3xgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training, should take around 20 minutes for 3 epochs\n",
        "history = classifier.fit(\n",
        "    train_dataset,\n",
        "    epochs=3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luwg1KM_3zJK",
        "outputId": "b86d0f6b-dcd7-4fe2-d430-36b3cd8d6b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "250/250 [==============================] - 348s 1s/step - loss: 0.9918 - accuracy: 0.6450\n",
            "Epoch 2/3\n",
            "250/250 [==============================] - 277s 1s/step - loss: 0.1956 - accuracy: 0.9259\n",
            "Epoch 3/3\n",
            "250/250 [==============================] - 277s 1s/step - loss: 0.1069 - accuracy: 0.9520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on test dataset\n",
        "classifier.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk6ayhhK30Xs",
        "outputId": "c148396f-d09d-4ec4-93e3-d80c70e1014b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 18s 278ms/step - loss: 0.1953 - accuracy: 0.9200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19533739984035492, 0.9200000166893005]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}