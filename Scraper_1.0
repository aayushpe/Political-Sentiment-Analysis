import requests
from bs4 import BeautifulSoup

def find_scraper(link):
    print("XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX   Reached find_scraper   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX")
    print(link)
    if "nbcnews.com" in link:
        print("\n\n From NBC")
        return scrape_method_1(link)
    if "dailycaller.com" in link:
        print("\n\n From DailyCaller")
        return scrape_method_1(link)
    if "newsweek.com" in link:
        return scrape_method_1(link)
    if "nytime.com" in link:
        return scrape_method_3(link)

def scrape_method_1(url):
    print("reached scrape_method_1")
    try:
        # Send a GET request to the URL
        response = requests.get(url)
        response.raise_for_status()  # Raise an exception for HTTP errors

        # Parse the HTML content of the page
        soup = BeautifulSoup(response.text, "html.parser")

        article_body_div = soup.find('div', class_ =['article-body', 'article-body v_text', 'article-content mb-2 pb-2 tracking-tight', 'article-content'])
        article_contents = article_body_div.find_all("p")

        article_text = ""
        if article_contents:
            for content in article_contents:
                article_text += content.text.strip()
                article_text += " "
        else:
            print("p_tags not found")
        return article_text


    except Exception as e:
        print("Error scraping article:", e)
        return None
def scrape_method_2(url):
    print("reached scrape_method_2")
    try:
        # Send a GET request to the URL
        response = requests.get(url)
        response.raise_for_status()  # Raise an exception for HTTP errors

        # Parse the HTML content of the page
        soup = BeautifulSoup(response.text, "html.parser")

        article_body_div = soup.find('div', class_ ='article-content mb-2 pb-2 tracking-tight')
        article_contents = article_body_div.find_all("p")

        article_text = ""
        if article_contents:
            for content in article_contents:
                article_text += content.text.strip()
                article_text += " "
        else:
            print("p_tags not found")
        return article_text


    except Exception as e:
        print("Error scraping article:", e)
        return None

def scrape_method_3(url):
    print("reached scrape_method_3")
    try:
        driver = webdriver.Chrome()

        driver.get(url)
        
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, "html.parser")
        target_divs = soup.find_all("div", class_="css-s99gbd StoryBodyCompanionColumn")

        article_text = ""
        
        for div in target_divs:
            paragraphs = div.find_all("p")
            for paragraph in paragraphs:
                article_text += content.text.strip()
                article_text += " "
        driver.quit()
    except Exception as e:
        print("Error scraping article:", e)
        return None

# URL of the page to scrape
#url = "https://www.allsides.com/story/politics-senate-renews-fisa-bipartisan-support-and-opposition"
url = "https://www.allsides.com/story/donald-trump-jury-hears-opening-statements-trump-s-hush-money-trial"

# Send a GET request to the URL
response = requests.get(url)

# Parse the HTML content of the page
soup = BeautifulSoup(response.text, "html.parser")


from_the_left = soup.find_all("div", class_="news-item left")

for div in from_the_left:
    title_sections = div.find_all("a")
    article_title = title_sections[0].text.strip()
    print("\nArticle Title:")
    print(article_title)

    print("Article Link:")
    link = [a.get('href') for a in title_sections]
    print(link[0])

    img_tag = div.find_all('img', {'title': True})
    if img_tag:
        left_rating = [word['title'] for word in img_tag]
        print("BIAS:")
        print(left_rating)

    print(find_scraper(link[0]))
        


else:
    print("Left item not found.")


from_the_center = soup.find_all("div", class_="news-item center")

for div in from_the_center:
    title_sections = div.find_all("a")
    article_title = title_sections[0].text.strip()

    print("\nArticle Title:")
    print(article_title)

    print("Article Link:")
    link = [a.get('href') for a in title_sections]
    print(link[0])

    img_tag = div.find_all('img', {'title': True})
    if img_tag:
        center_rating = [word['title'] for word in img_tag]
        print("BIAS:")
        print(center_rating)
    print(find_scraper(link[0]))



from_the_right = soup.find_all("div", class_="news-item right")

for div in from_the_right:
    title_sections = div.find_all("a")
    article_title = title_sections[0].text.strip()

    print("\nArticle Title:")
    print(article_title)

    print("Article Link:")
    link = [a.get('href') for a in title_sections]
    print(link[0])
    
    img_tag = div.find_all('img', {'title': True})
    if img_tag:
        center_rating = [word['title'] for word in img_tag]
        print("BIAS:")
        print(center_rating)
    print(find_scraper(link[0]))
